{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, num_topics, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        if topic_idx < num_topics:\n",
    "            print(\"{:11}\".format(\"Topic %d:\" %(topic_idx)), end='')\n",
    "            print(\", \".join(['{:04.3f}*'.format(topic[i])+feature_names[i] \\\n",
    "                             for i in topic.argsort()[:-no_top_words-1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>text</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>5</td>\n",
       "      <td>Firstly, this restaurant is in The Linq Hotel,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>4</td>\n",
       "      <td>This place had monsterous proportions OMG! One...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>5</td>\n",
       "      <td>This place freaking rocks. Must go to when in ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>3</td>\n",
       "      <td>Visited HHAGG ago go for the first time on 5/5...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Hash House A Go Go</td>\n",
       "      <td>3</td>\n",
       "      <td>Big portions. Sharing is highly recommended. H...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                name  stars_y  \\\n",
       "0           0  Hash House A Go Go        5   \n",
       "1           1  Hash House A Go Go        4   \n",
       "2           2  Hash House A Go Go        5   \n",
       "3           3  Hash House A Go Go        3   \n",
       "4           4  Hash House A Go Go        3   \n",
       "\n",
       "                                                text  userid  \n",
       "0  Firstly, this restaurant is in The Linq Hotel,...       0  \n",
       "1  This place had monsterous proportions OMG! One...       1  \n",
       "2  This place freaking rocks. Must go to when in ...       2  \n",
       "3  Visited HHAGG ago go for the first time on 5/5...       3  \n",
       "4  Big portions. Sharing is highly recommended. H...       4  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Data\n",
    "data = pd.read_csv('hash_house.csv')\n",
    "data['userid'] = data['Unnamed: 0']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split reviews into individual sentences \n",
    "df = pd.DataFrame(columns=['userid','sentence','stars'])\n",
    "for i in range(0,len(data),1):\n",
    "    sentences = tokenize.sent_tokenize(data.text[i])\n",
    "    for j in sentences:\n",
    "        df = df.append({'userid':data.userid[i],'sentence':j,'stars':data.stars_y[i]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>sentence</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Firstly, this restaurant is in The Linq Hotel,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Expect a line.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Waited only about 15 minutes to be seated, tho...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Greeted by Tony our waiter who was really warm...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Ordered the Sage Fried Chicken and Waffles.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userid                                           sentence stars\n",
       "0      0  Firstly, this restaurant is in The Linq Hotel,...     5\n",
       "1      0                                     Expect a line.     5\n",
       "2      0  Waited only about 15 minutes to be seated, tho...     5\n",
       "3      0  Greeted by Tony our waiter who was really warm...     5\n",
       "4      0        Ordered the Sage Fried Chicken and Waffles.     5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpus for TFIDF\n",
    "corpus = []\n",
    "for i in df.sentence:\n",
    "        corpus.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Topics\n",
    "### 3 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: food good great service place wait amazing vegas really time breakfast worth just delicious definitely\n",
      "Topic #1: chicken waffles fried sage benedict ordered bacon got eggs delicious hash waffle andy potatoes amazing\n",
      "Topic #2: huge portions large delicious big share portion food people prices plate massive enormous tasty hungry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 3\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: food great service place wait amazing vegas time delicious worth breakfast definitely just come long\n",
      "Topic #1: chicken waffles fried sage benedict ordered bacon got eggs delicious hash andy waffle potatoes amazing\n",
      "Topic #2: huge portions large big delicious share portion people food prices plate massive enormous tasty hungry\n",
      "Topic #3: good really service pretty food just overall potatoes biscuits thing bloody mary taste coffee biscuit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 4\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: food great service amazing delicious awesome excellent friendly man vs just price came server experience\n",
      "Topic #1: chicken waffles fried sage benedict ordered bacon got eggs delicious andy waffle potatoes amazing hash\n",
      "Topic #2: huge portions large big delicious share portion people prices plate massive enormous food hungry tasty\n",
      "Topic #3: good really pretty service food just overall potatoes biscuits bloody thing mary taste coffee biscuit\n",
      "Topic #4: place wait vegas worth time definitely breakfast come hash try long house love eat minutes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 5\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: great service friendly place excellent experience customer staff slow server fast atmosphere breakfast attentive awesome\n",
      "Topic #1: chicken waffles fried sage benedict ordered bacon got eggs delicious andy waffle potatoes hash crispy\n",
      "Topic #2: huge portions large big share portion delicious people prices plate massive enormous hungry meal tasty\n",
      "Topic #3: good really service pretty overall just potatoes biscuits bloody thing mary taste coffee biscuit eggs\n",
      "Topic #4: place wait vegas worth time definitely breakfast come hash try long house love eat minutes\n",
      "Topic #5: food amazing delicious man vs awesome just came lot price excellent took quality tasty large\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 6\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: great service friendly excellent experience staff customer slow server fast atmosphere attentive waiter quick bad\n",
      "Topic #1: chicken waffles fried sage benedict ordered bacon got eggs delicious andy waffle potatoes crispy hash\n",
      "Topic #2: huge portions large big share portion delicious people prices plate massive enormous hungry meal tasty\n",
      "Topic #3: good really pretty service overall just potatoes biscuits bloody thing mary taste coffee biscuit wasn\n",
      "Topic #4: place vegas breakfast definitely hash love house try time come eat best recommend just las\n",
      "Topic #5: food amazing delicious man vs awesome just came lot price excellent took quality tasty large\n",
      "Topic #6: wait worth long time minutes hour seated 30 table minute 45 20 come definitely 10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 7\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: great service friendly excellent experience staff customer slow server fast atmosphere attentive waiter quick bad\n",
      "Topic #1: chicken waffles fried sage benedict ordered bacon got eggs andy waffle potatoes crispy amazing hash\n",
      "Topic #2: huge portions large big share portion people prices plate massive hungry enormous meal tasty size\n",
      "Topic #3: good really pretty service overall just potatoes biscuits bloody thing mary taste coffee biscuit looked\n",
      "Topic #4: place vegas breakfast definitely hash love try house time come eat best recommend just las\n",
      "Topic #5: food amazing man vs awesome just came lot price excellent took quality tasty large like\n",
      "Topic #6: wait worth long time minutes hour seated 30 table minute 45 20 come definitely 10\n",
      "Topic #7: delicious absolutely bloody mary hash biscuit potatoes pancake fresh house looked coffee bacon biscuits crispy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 8\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: great service friendly excellent experience staff customer slow server fast atmosphere attentive waiter quick breakfast\n",
      "Topic #1: chicken waffles fried sage benedict ordered bacon got eggs andy waffle potatoes amazing crispy best\n",
      "Topic #2: huge portions large big share portion people prices plate massive hungry enormous meal tasty size\n",
      "Topic #3: good really pretty service overall just potatoes biscuits bloody thing mary taste coffee looked wasn\n",
      "Topic #4: place vegas definitely breakfast love try come recommend time eat best awesome amazing just las\n",
      "Topic #5: food amazing man vs awesome just came lot price excellent took quality tasty like large\n",
      "Topic #6: wait worth long time minutes hour seated 30 definitely table come minute 45 20 10\n",
      "Topic #7: delicious absolutely bloody mary biscuit potatoes pancake fresh looked coffee bacon biscuits crispy tried toast\n",
      "Topic #8: hash house vegas beef corned time ordered breakfast eggs linq love potatoes chorizo got meatloaf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 9\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: great service friendly experience excellent customer staff slow server fast atmosphere attentive waiter quick nice\n",
      "Topic #1: chicken waffles fried sage benedict ordered bacon got eggs andy waffle potatoes crispy best try\n",
      "Topic #2: huge portions large big share portion people prices plate massive hungry enormous meal tasty size\n",
      "Topic #3: good really pretty service overall just potatoes biscuits bloody thing mary taste coffee looked wasn\n",
      "Topic #4: place vegas definitely breakfast love try come time recommend eat best awesome just las visit\n",
      "Topic #5: food man vs awesome just came lot price excellent like took quality tasty large big\n",
      "Topic #6: wait worth long time minutes hour seated 30 table definitely come minute 45 20 10\n",
      "Topic #7: delicious absolutely bloody mary biscuit potatoes pancake fresh looked coffee bacon biscuits crispy tried toast\n",
      "Topic #8: hash house vegas beef corned time ordered breakfast eggs linq love potatoes chorizo got meatloaf\n",
      "Topic #9: amazing breakfast service absolutely staff server mary say bloody restaurant meatloaf looked potatoes meal drinks\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 10\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
