{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import string\n",
    "import statsmodels.api as sm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from nltk import tokenize\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_topics(model, feature_names, num_topics, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        if topic_idx < num_topics:\n",
    "            print(\"{:11}\".format(\"Topic %d:\" %(topic_idx)), end='')\n",
    "            print(\", \".join(['{:04.3f}*'.format(topic[i])+feature_names[i] \\\n",
    "                             for i in topic.argsort()[:-no_top_words-1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xinro\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>review_count</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>categories</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>userid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>PZ-LZzSlhSe9utkQYU8pFg</td>\n",
       "      <td>Carluccio's Tivoli Gardens</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89119.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-06-29 02:55:07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>klcF45wKIOpJW_BhJslOJg</td>\n",
       "      <td>5.0</td>\n",
       "      <td>We went there for dinner the other night, bein...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-Yz2wIcsdJxUOFMbTgoKQA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PZ-LZzSlhSe9utkQYU8pFg</td>\n",
       "      <td>Carluccio's Tivoli Gardens</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89119.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-10-06 18:20:13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Li-pQG6A7p5gbgZHTMeDSQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>i had the best Chicken Marcela ever. The spagh...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>jYcf_e5p0UG0S-9gJq_tNA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>PZ-LZzSlhSe9utkQYU8pFg</td>\n",
       "      <td>Carluccio's Tivoli Gardens</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89119.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2010-01-13 00:35:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>iRLX3dJ3ONvncIxPnXy1cw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Basically the best Italian in town for the pri...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nQC0JiPIk_jCooRDxpuw5A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>PZ-LZzSlhSe9utkQYU8pFg</td>\n",
       "      <td>Carluccio's Tivoli Gardens</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89119.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-08-23 20:30:33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>rklteWf9xnTU3fAtMFBRRw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Mmmmm delicious food and a little history. Mr....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gv_-mtOKhWFtCjn9xFe0SQ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>PZ-LZzSlhSe9utkQYU8pFg</td>\n",
       "      <td>Carluccio's Tivoli Gardens</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>89119.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Restaurants, Italian</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009-06-01 20:02:55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>UfRqM0RGdZa86hFcFEAnjw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>This is old Vegas, this atmosphere is old scho...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pabMYegF28KjHQ5hybAJ0A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Unnamed: 0             business_id                        name       city  \\\n",
       "0          0  PZ-LZzSlhSe9utkQYU8pFg  Carluccio's Tivoli Gardens  Las Vegas   \n",
       "1          1  PZ-LZzSlhSe9utkQYU8pFg  Carluccio's Tivoli Gardens  Las Vegas   \n",
       "2          2  PZ-LZzSlhSe9utkQYU8pFg  Carluccio's Tivoli Gardens  Las Vegas   \n",
       "3          3  PZ-LZzSlhSe9utkQYU8pFg  Carluccio's Tivoli Gardens  Las Vegas   \n",
       "4          4  PZ-LZzSlhSe9utkQYU8pFg  Carluccio's Tivoli Gardens  Las Vegas   \n",
       "\n",
       "  state  postal_code  review_count  stars_x            categories  cool  \\\n",
       "0    NV      89119.0          40.0      4.0  Restaurants, Italian   0.0   \n",
       "1    NV      89119.0          40.0      4.0  Restaurants, Italian   0.0   \n",
       "2    NV      89119.0          40.0      4.0  Restaurants, Italian   0.0   \n",
       "3    NV      89119.0          40.0      4.0  Restaurants, Italian   0.0   \n",
       "4    NV      89119.0          40.0      4.0  Restaurants, Italian   0.0   \n",
       "\n",
       "                  date  funny               review_id  stars_y  \\\n",
       "0  2011-06-29 02:55:07    0.0  klcF45wKIOpJW_BhJslOJg      5.0   \n",
       "1  2010-10-06 18:20:13    0.0  Li-pQG6A7p5gbgZHTMeDSQ      4.0   \n",
       "2  2010-01-13 00:35:45    0.0  iRLX3dJ3ONvncIxPnXy1cw      5.0   \n",
       "3  2008-08-23 20:30:33    0.0  rklteWf9xnTU3fAtMFBRRw      3.0   \n",
       "4  2009-06-01 20:02:55    0.0  UfRqM0RGdZa86hFcFEAnjw      3.0   \n",
       "\n",
       "                                                text  useful  \\\n",
       "0  We went there for dinner the other night, bein...     1.0   \n",
       "1  i had the best Chicken Marcela ever. The spagh...     1.0   \n",
       "2  Basically the best Italian in town for the pri...     1.0   \n",
       "3  Mmmmm delicious food and a little history. Mr....     1.0   \n",
       "4  This is old Vegas, this atmosphere is old scho...     1.0   \n",
       "\n",
       "                  user_id userid  \n",
       "0  -Yz2wIcsdJxUOFMbTgoKQA      0  \n",
       "1  jYcf_e5p0UG0S-9gJq_tNA      1  \n",
       "2  nQC0JiPIk_jCooRDxpuw5A      2  \n",
       "3  Gv_-mtOKhWFtCjn9xFe0SQ      3  \n",
       "4  pabMYegF28KjHQ5hybAJ0A      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Data\n",
    "data = pd.read_csv('vegas.csv')\n",
    "data['userid'] = data['Unnamed: 0']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['postal_code'] == 89103].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60974"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split reviews into individual sentences \n",
    "df = pd.DataFrame(columns=['userid','sentence','stars'])\n",
    "for i in range(50000,60974,1):\n",
    "    sentences = tokenize.sent_tokenize(data.text[i])\n",
    "    for j in sentences:\n",
    "        df = df.append({'userid':data.userid[i],'sentence':j,'stars':data.stars_y[i]},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpus for TFIDF\n",
    "corpus_6 = []\n",
    "for i in df.sentence:\n",
    "        corpus_6.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_6 = pd.read_csv('89103_6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in df.sentence:\n",
    "        corpus.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "df.to_csv('89103_2.csv')\n",
    "#corpus_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "df.to_csv('89103_3.csv')\n",
    "#corpus_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "df.to_csv('89103_4.csv')\n",
    "#corpus_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "df.to_csv('89103_5.csv')\n",
    "#corpus_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "df.to_csv('89103_6.csv')\n",
    "#corpus_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Corpus for TFIDF\n",
    "corpus = []\n",
    "corpus = corpus_1+corpus_2+corpus_3+corpus_4+corpus_5+corpus_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: great experience atmosphere prices price overall staff selection view sushi meal deal value flavor music\n",
      "Topic #1: good really pretty price overall prices flavor thing experience selection quality chicken taste portions tasted\n",
      "Topic #2: place love recommend amazing try awesome highly clean stars favorite eat sushi new nice looking\n",
      "Topic #3: food delicious amazing fresh quality excellent fast authentic chinese mexican awesome ok price tasty thai\n",
      "Topic #4: service friendly excellent customer fast staff attentive slow nice amazing bad horrible quick awesome terrible\n",
      "Topic #5: time vegas just best like really ve restaurant buffet don order eat las came didn\n",
      "Topic #6: definitely come recommend try coming ll worth highly return vegas visit going town wait soon\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_components = 7\n",
    "n_top_words = 15\n",
    "\n",
    "# TFIDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# NMF reduction\n",
    "nmf = NMF(n_components=n_components).fit(tfidf)\n",
    "W_pos = nmf.fit_transform(tfidf)\n",
    "\n",
    "# Output Topics\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Topic #0: Overall experience\n",
    "- Topic #1: Price\n",
    "- Topic #2: \"Worth it\"\n",
    "- Topic #3: Food\n",
    "- Topic #4: Service\n",
    "- Topic #5: \n",
    "- Topic #6: \"Worth it\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "path =r'C:\\Users\\xinro\\Downloads\\89103' # use your path\n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_)\n",
    "df = frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Topic with highest score\n",
    "array = []\n",
    "# For all NMF array\n",
    "for i in range(0,len(W_pos),1):\n",
    "    # Create dictionary with Topics and its NMF scores for each sentence\n",
    "    topic_dict = {}\n",
    "    # Drop sentences that have length less than 10 by setting topic to -1\n",
    "    if len(corpus[i])>=10:\n",
    "        for ind, w in enumerate(W_pos[i]):\n",
    "            topic_dict[ind] = w\n",
    "        # Classify sentence to the topic with highest score\n",
    "        array.append(max(topic_dict, key=topic_dict.get))\n",
    "    else:\n",
    "        array.append(-1)\n",
    "# Create new column in df for topic\n",
    "df['Topic'] = array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veder Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Sentiment Intensity Analyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append Sentiment Intensity Scores for each sentence\n",
    "array = []\n",
    "for i in df.sentence:\n",
    "    # Generate Sentiment Intensity Scores and store in array\n",
    "    score = analyser.polarity_scores(i)\n",
    "    array.append(score['compound'])\n",
    "# Create new column in df for sentiment intensity score\n",
    "df['sentiment'] = array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Final df of intensity scores\n",
    "df_scores = pd.DataFrame(columns=['userid','0','1','2','3','4','5','6','stars'])\n",
    "# For every user aggregate the sentiment scores by topic\n",
    "for i in df.userid.unique():\n",
    "    # Create df of scores from same user\n",
    "    temp_df = df[df.userid==i].reset_index(drop=True)\n",
    "    # For every topic\n",
    "    topic_score = []\n",
    "    for j in range(0,7,1):\n",
    "        score = 0\n",
    "        count = 0\n",
    "        for k in range(0,len(temp_df),1):\n",
    "            # If topic equal to current topic\n",
    "            if temp_df.Topic[k] == j:\n",
    "                # Add sentiment score\n",
    "                score = score + temp_df.sentiment[k]\n",
    "                # Increase count\n",
    "                count = count + 1\n",
    "        # If count = 0 then no score for topic\n",
    "        if count==0:\n",
    "            topic_score.append(0)\n",
    "        # Else append average score for topic\n",
    "        else:\n",
    "            topic_score.append(score/count)\n",
    "    # Insert UserId and Star Rating \n",
    "    topic_score.insert(0,temp_df.userid[0])\n",
    "    topic_score.insert(len(topic_score),temp_df.stars[0])\n",
    "    # Transform and Append into main df\n",
    "    temp = pd.DataFrame(pd.Series(topic_score))\n",
    "    temp = temp.transpose()\n",
    "    temp.columns = df_scores.columns\n",
    "    df_scores = df_scores.append(temp,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1248.0</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.22350</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1249.0</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>0.4663</td>\n",
       "      <td>0.72705</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>0.64650</td>\n",
       "      <td>0.4201</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1250.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.15434</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1251.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.8655</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.50685</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1252.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.12530</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>0.49390</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userid       0       1        2       3       4        5       6  stars\n",
       "0  1248.0  0.8779  0.0000  0.00000  0.0000  0.6249  0.22350  0.0000    5.0\n",
       "1  1249.0  0.7579  0.4663  0.72705  0.0000  0.8271  0.64650  0.4201    5.0\n",
       "2  1250.0  0.0000  0.0000  0.00000  0.0000  0.0000  0.15434  0.0000    5.0\n",
       "3  1251.0  0.0000  0.0000  0.00000  0.8655  0.0000  0.50685  0.0000    5.0\n",
       "4  1252.0  0.0000  0.0000  0.12530  0.0000  0.8074  0.49390  0.0000    5.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into predictors and target\n",
    "X = df_scores.drop(['userid','stars'],axis=1)\n",
    "X = X.astype(float)\n",
    "y = df_scores.stars\n",
    "y = y.astype(float)\n",
    "# Split Train vs Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=1)\n",
    "# Split Test set into validation & test set\n",
    "X_test2, X_val, y_test2, y_val = train_test_split(X_test,y_test,test_size=0.5,stratify=y_test,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Simple linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "const    2.761842\n",
      "0        0.673569\n",
      "1        0.488325\n",
      "2        0.823065\n",
      "3        1.055124\n",
      "4        0.996302\n",
      "5        1.825861\n",
      "6        0.674795\n",
      "dtype: float64\n",
      "\n",
      "Mean Squared Error:  1.1923921339959864\n",
      "AIC:  147812.53528216275\n"
     ]
    }
   ],
   "source": [
    "model = sm.OLS(y_train,sm.add_constant(X_train)).fit()\n",
    "print(model.params)\n",
    "print()\n",
    "print('Mean Squared Error: ',mean_squared_error(y_val,model.predict(sm.add_constant(X_val))))\n",
    "print('AIC: ',model.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Topic #0: Overall experience\n",
    "- Topic #1: Price\n",
    "- Topic #2: \"Worth it\"\n",
    "- Topic #3: Food\n",
    "- Topic #4: Service\n",
    "- Topic #5: \n",
    "- Topic #6: \"Worth it\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ùë¶‚Ñéùëéùë°=2.76+0.67‚àóOverall+0.49‚àóPrice+0.82‚àóùëäùëúùëüùë°‚Ñé+1.06‚àóùêπùëúùëúùëë+1.00‚àóService+1.83‚àóTopic5+0.67‚àóWorth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removed Intercept and Non-Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.232742\n",
      "1    2.921851\n",
      "2    2.292232\n",
      "3    2.706688\n",
      "5    4.302188\n",
      "6    2.215236\n",
      "dtype: float64\n",
      "\n",
      "Mean Squared Error:  4.961835852693974\n",
      "AIC:  215712.09669405263\n"
     ]
    }
   ],
   "source": [
    "# Split into predictors and target\n",
    "X = df_scores.drop(['userid','stars','4'],axis=1)\n",
    "X = X.astype(float)\n",
    "y = df_scores.stars\n",
    "y = y.astype(float)\n",
    "# Split Train vs Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=1)\n",
    "# Split Test set into validation & test set\n",
    "X_test2, X_val, y_test2, y_val = train_test_split(X_test,y_test,test_size=0.5,stratify=y_test,random_state=1)\n",
    "\n",
    "model = sm.OLS(y_train,X_train).fit()\n",
    "print(model.params)\n",
    "print()\n",
    "print('Mean Squared Error: ',mean_squared_error(y_val,model.predict(X_val)))\n",
    "print('AIC: ',model.aic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
